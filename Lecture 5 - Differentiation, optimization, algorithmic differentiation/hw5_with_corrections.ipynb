{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "nbgrader",
      "language": "python",
      "name": "nbgrader"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYXrQEuHXyTW"
      },
      "source": [
        "Instructions:\n",
        "1. Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"\n",
        "2. Do not add or remove cells to the document, inside the current cells you can add helper functions if you wish.\n",
        "3. Download the file and submit only one file named hw5.ipynb (Do not change file name!)\n",
        "4. Work alone, you can use any resource that was presented in class!\n",
        "5. Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Runtime$\\rightarrow$Run All).\n",
        "6. Clear all outputs - Edit$\\rightarrow$Clear all outputs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMpDZmNRXyTb"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "-Ddvr3pHG4yc",
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7e28609ee8536d4770a5acd79467683e",
          "grade": false,
          "grade_id": "cell-d826f2a5211905e3",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "# Assignment 5: Differentiation and optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "_pVdjMLHG4yd",
        "nbgrader": {
          "cell_type": "code",
          "checksum": "68ac4d1b8278a50275435a7cdcb117d3",
          "grade": false,
          "grade_id": "cell-2c47810b587eba40",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "source": [
        "import sympy as sym # symbolic differentiation\n",
        "import jax          # algorithmic differentiation\n",
        "import jax.numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "5acfe76de27c1d2787061d5393c66a69",
          "grade": false,
          "grade_id": "cell-8e70e66cf8309900",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xzGYUlGYXyTc"
      },
      "source": [
        "## Question 1: Differentiation\n",
        "\n",
        "Function\n",
        "\n",
        "$$f(a, b) = \\frac 2 a sin(b) \\exp \\left( - \\frac {a^2} {b^2}\\right)$$\n",
        "\n",
        "is given."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "7c66850d2769109ae45e3fe88d5c41cd",
          "grade": false,
          "grade_id": "cell-8f63e6aeedb5c09b",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "aXmB2P2vXyTd"
      },
      "source": [
        "1. Derive the partial derivatives of $f(a, b)$ by $a$ and $b$.\n",
        "\n",
        "    $$\\frac {\\partial f} {\\partial a} = $$\n",
        "    $$\\frac {\\partial f} {\\partial b} = $$\n",
        "\n",
        "Implement the function f_partial_derviatives:\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "a - first symbol\n",
        "b - second symbol\n",
        "return value - a tuple (dfa, dfb) such that dfa is the partial derivatives of f by a,\n",
        "               and dfb is the partial derivative of f by b\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "80600e68fbd9a8fa065f02b6bd9b0baf",
          "grade": false,
          "grade_id": "cell-fcc26ea16c7fcc6e",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Bt4hqb2GXyTd"
      },
      "source": [
        "def f_partial_derviatives_symbol(a, b):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "786889cd0849242f4f30bd9a443f5dfd",
          "grade": true,
          "grade_id": "cell-910c1caba85f9efe",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "70X0oYqnXyTe"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q1.1 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'f_partial_derviatives_symbol' function..\\n \")\n",
        "a=sym.Symbol('a')\n",
        "b=sym.Symbol('b')\n",
        "f_deriv_a, f_deriv_b = f_partial_derviatives_symbol(a, b)\n",
        "assert isinstance(f_deriv_a, sym.Basic)\n",
        "assert isinstance(f_deriv_b, sym.Basic)\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n",
        "print(f\"Dervative with respect to a is: {f_deriv_a}\")\n",
        "print(f\"Dervative with respect to b is: {f_deriv_b}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "19358409e08ee5150391dee7d8699370",
          "grade": false,
          "grade_id": "cell-5cbb42199eaf95ef",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "MN3Qkp1IXyTe"
      },
      "source": [
        "2. Derive the same derivatives by a and b, but using using algorithmic differentiation this time (with `jax`).\n",
        "\n",
        "Implement the function f, and f_partial_derviatives_algo:\n",
        "\n",
        "<pre>\n",
        "f:\n",
        "Input parameters:\n",
        "a,b - point (a,b)\n",
        "return value - the output of the equation of Question 1\n",
        "\n",
        "f_partial_derviatives_algo:\n",
        "Input parameters:\n",
        "f - a function\n",
        "a,b - point(a,b)\n",
        "return value - a tuple (dfa, dfb) such that dfa is the partial derivatives of f by a,\n",
        "               and dfb is the partial derivative of f by b\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e4ce43ce84665c666cc4367cd4d75f16",
          "grade": false,
          "grade_id": "cell-68ca280308184043",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "3mdpRFjUXyTf"
      },
      "source": [
        "def f(a, b):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "def f_partial_derviatives_algo(f, a ,b):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed15d3176f8ccbaf8deebdb1f1b6e175",
          "grade": true,
          "grade_id": "cell-bf714cb7381ed64d",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "91XTOjo-XyTf"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q1.2 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'f_partial_derviatives_algo' function..\\n \")\n",
        "a=1.\n",
        "b=1.\n",
        "f_deriv_a, f_deriv_b = f_partial_derviatives_algo(f, a, b)\n",
        "assert callable(f_deriv_a)\n",
        "assert callable(f_deriv_b)\n",
        "assert f_deriv_a(a, b) < 0\n",
        "assert f_deriv_b(a, b) > 0\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n",
        "print(f\"Dervative with respect to a is: {f_deriv_a(a,b)}\")\n",
        "print(f\"Dervative with respect to b is: {f_deriv_b(a,b)}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "e234237cf36aabcca272f450f45a879f",
          "grade": false,
          "grade_id": "cell-2f70f1b68a8a3397",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "3xzJRRJ9XyTf"
      },
      "source": [
        "3. Plot the following:\n",
        "\n",
        "a. One subplot for both:\n",
        "\n",
        "  * $f(a, 10)$, $\\frac {\\partial f(a, 10)} {\\partial a}$ for range $a \\in [-20, 20]$,\n",
        "\n",
        "b. A seperate subplot below the first subplot for:\n",
        "\n",
        "  * $f(10, b)$, $\\frac {\\partial f(10, b)} {\\partial b}$ for range $b \\in [1, 100]$.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ee87320d9fe95a363022b938145f6f5d",
          "grade": true,
          "grade_id": "cell-7c4c505ac0fa2e26",
          "locked": false,
          "points": 2,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "LtfniyKQXyTg"
      },
      "source": [
        "# show you plots here:\n",
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f8033254cb6c569ca12a1c2b7d1e6a6b",
          "grade": false,
          "grade_id": "cell-d41582685181dca1",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "FhKmgAcPXyTg"
      },
      "source": [
        "4. Implement a function for approximate numerical differentiation, given the difference size $h$.\n",
        "\n",
        "Implement the function f_partial_derviatives_numeric_at_a_b:\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "f - function f\n",
        "a - first parameter of f\n",
        "b - second parameter of f\n",
        "h - the change of the variable to approximate the derivative by\n",
        "return value - a tuple that contains partial derivatives of f by a and b approximated at (a,b)\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a05425f84b97d3f347c1f3c82b4a2214",
          "grade": false,
          "grade_id": "cell-1dc99d4eaa406e89",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "hYx3JMg6XyTh"
      },
      "source": [
        "def f_partial_derviatives_numeric_at_a_b(f, a, b, h):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4eb71eab53355a28e5d61b8d34358c6b",
          "grade": true,
          "grade_id": "cell-f9a81b3184e827ab",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "z56XLhUkXyTh"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q1.4 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'f_partial_derviatives_numeric' function..\\n \")\n",
        "a=1.\n",
        "b=1.\n",
        "f_deriv_a_at_a_b, f_deriv_b_at_a_b = f_partial_derviatives_numeric_at_a_b(f, a, b, 1e-6)\n",
        "assert f_deriv_a_at_a_b < 0\n",
        "assert f_deriv_b_at_a_b > 0\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b269e94a9851cc15881552aec439ff36",
          "grade": false,
          "grade_id": "cell-6f154f57c695e08e",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "S0gex10bXyTh"
      },
      "source": [
        "5. Find the best difference size $h$ for differentiating\n",
        "   * $f(a, b)$ by $a$.\n",
        "   * $f(a, b)$ by $b$.\n",
        "\n",
        "The best difference size minimizes the absolute error of numerical differentiation relative to the exact differentiation.\n",
        "\n",
        "Implement the function f_deriv_by_a_optimize_h:\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "a - first parameter of f\n",
        "b - second parameter of f\n",
        "return value - the absoltue difference between the vaule of the derivative using the best difference h to do numeric differentiation of f(a,b) by a and the algorithmic derivative by a\n",
        "</pre>\n",
        "\n",
        "Implement the function f_deriv_by_b_optimize_h:\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "a - first parameter of f\n",
        "b - second parameter of f\n",
        "return value - the absoltue difference between the vaule of the derivative using the best difference h to do numeric differentiation of f(a,b) by b and the algorithmic derivative by b\n",
        "</pre>\n",
        "\n",
        "Non-Mandatory: draw plots of the abolute error by h\n",
        "(it's a good practice for you to validate that the results make sense)\n",
        "\n",
        "* Allowed relative tolerance is up to 100 (so if best h=1e-04, any value between 1e-02 and 1e-06 is allowed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "920a2cce72f823d4b3e31c29c48ac272",
          "grade": false,
          "grade_id": "cell-1bd9e03b2999d29f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "y43U-pVkXyTi"
      },
      "source": [
        "def f_deriv_by_a_optimize_h(a, b):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d4df9aee6d7ee97ade14d13e6743552f",
          "grade": false,
          "grade_id": "cell-aafc10f1c62a469a",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "UAN7y5HJXyTj"
      },
      "source": [
        "def f_deriv_by_b_optimize_h(a, b):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8ef50f28ac8b9242fc89ed47f93fbfec",
          "grade": true,
          "grade_id": "cell-65a8e984bababd74",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "un6ixXjfXyTj"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q1.5 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'f_partial_derviatives_numeric' function..\\n \")\n",
        "assert f_deriv_by_a_optimize_h(a,b) < 1e-04\n",
        "assert f_deriv_by_b_optimize_h(a,b) < 1e-04\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "b289fe25b06385665a5b837b797c3a07",
          "grade": false,
          "grade_id": "cell-89f9f7e53914ff2a",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "o5l1m0bfXyTj"
      },
      "source": [
        "## Question 2: Optimization\n",
        "\n",
        "### Logistic regression\n",
        "\n",
        "For a trial group of rats https://en.wikipedia.org/wiki/Rat , the weight and the event of having diabetes are given as a list of pairs (weight, diabetes) (1 corresponds to diabetes):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2761d5c514a701224fc4f10bcdb23660",
          "grade": false,
          "grade_id": "cell-5a43cf6adc2e93f6",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "2-VOlcvgXyTj"
      },
      "source": [
        "rats = [(0.47, 0), (0.23, 0), (0.86, 1), (0.22, 0), (0.21, 1),\n",
        "        (0.31, 0), (0.62, 0), (0.941, 1), (0.27, 0), (0.35, 1),\n",
        "        (0.18, 0), (0.13, 0), (0.31, 1), (0.99, 1), (0.85, 1),\n",
        "        (0.35, 1), (0.6, 1), (0.89, 0), (0.6, 1), (0.92, 0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a2fa05f56266446f3bd0b564aa1ba866",
          "grade": false,
          "grade_id": "cell-c03650829efcf55d",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Kf1WKF4TXyTk"
      },
      "source": [
        "Logistic regression is a statiscal model that models the probability of an event happening. In binary logistic regression there is a single binary dependent variable coded by '0' or '1'.\n",
        "\n",
        "We can express the data as a tuple $(x,y)=(data,outcome)=(x,0/1)$\n",
        "\n",
        "To model the probability of event $x$, we can use the logistic function $p(x)=\\frac{1}{1+e^{(\\mu-x)}}$.\n",
        "\n",
        "To find the appropiate $\\mu$, that maximizes the classifaction accuracy we minimize the loss function $-\\sum_{i=1}^N (y_i \\log p(x_i) + (1 - y_i) \\log (1 - p(x_i)))$.\n",
        "\n",
        "----------------------------------------\n",
        "\n",
        "\n",
        "We want to predict rat diabetes based on weight. The prediction function is\n",
        "\n",
        "$$diabetes = {weight} \\ge threshold.$$\n",
        "\n",
        "The loss for this _classification_ problem is called log_loss:\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "& L = -\\sum_{i=1}^N (diabetes_i \\log p_i + (1 - diabetes_i) \\log (1 - p_i))\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "where the predicted probability is:\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "& p_i = \\frac 1 {1 + \\exp(threshold - weight{_i})}\n",
        "\\end{aligned}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "0216222f9a19f37697b90d9833949521",
          "grade": false,
          "grade_id": "cell-07381a88c978e1fe",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "UY9ZFwY1XyTk"
      },
      "source": [
        "1. Implement the loss as a function of the threshold.\n",
        "\n",
        "Implement the function care_bare_classification_loss:\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "threshold - the treshold of the classification\n",
        "data - the data in the format of list of tuples\n",
        "return value - the loss as defined above\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "69bd9fadddfc9fc5f58027576dc2b87f",
          "grade": false,
          "grade_id": "cell-da55752637b08a28",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "LF3x0HydXyTl"
      },
      "source": [
        "def rat_classification_loss(threshold, data=rats):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "da185926db5a90fbc8331d6360160a4b",
          "grade": true,
          "grade_id": "cell-1e51ea7117c6868f",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "xY1Se9TAXyTl"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q2.1 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'loss' function..\\n \")\n",
        "assert rat_classification_loss(0.5) > 0\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "d5a3342bab2991778a107e2b972e1a14",
          "grade": false,
          "grade_id": "cell-895b78311fff1ecb",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "btfDCVo2XyTl"
      },
      "source": [
        "2. Plot the loss and the derivative of the loss by the threshold in the range $threshold \\in (0.01, 0.99)$\n",
        "\n",
        "Implement a function rat_classification_loss_deriv\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "threshold - the treshold of the classification\n",
        "return value - the derviative of the loss\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "321af0fa872fe6d6d960c10b34b0776c",
          "grade": false,
          "grade_id": "cell-9e65d966d3fe2745",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "Imp8BOT8XyTm"
      },
      "source": [
        "def rat_classification_loss_deriv(threshold):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "72cc6e1e04635a89ce9dcb48a820ee57",
          "grade": true,
          "grade_id": "cell-779160dbb3fa5fbf",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "iZetuHD1XyTm"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q2.2 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'loss' function..\\n \")\n",
        "assert rat_classification_loss_deriv(0.5) < 0\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "c163230004110b517584ac8434ab4f2a",
          "grade": false,
          "grade_id": "cell-e344ecace17a1cef",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "PTws6oiBXyTm"
      },
      "source": [
        "3. Find the best threshold using gradient descent - use jax for the dervative!\n",
        "\n",
        "Implement a function loss_best_threshold_gd\n",
        "\n",
        "<pre>\n",
        "return value - the best threshold according to the loss function\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "73887ee8fb7806c138e378d461a64629",
          "grade": false,
          "grade_id": "cell-252b27d3b325b9e9",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "cdO0IHP3XyTm"
      },
      "source": [
        "def loss_best_threshold_gd(f, x0=0., step=0.1, decay=0.995, niter=30):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "c597730834adc49a5d793a86872c7122",
          "grade": true,
          "grade_id": "cell-7e98f7a26296840a",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "L0QdyYvkXyTn"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q2.3 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'loss' function..\\n \")\n",
        "best_threshold = loss_best_threshold_gd(rat_classification_loss_deriv)\n",
        "assert best_threshold > 0\n",
        "assert rat_classification_loss(best_threshold) < rat_classification_loss(best_threshold+0.5)\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n",
        "print(f\"Best threshold: best_threshold\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "bd00dbd95d003dfbe2f038641e3ce6df",
          "grade": false,
          "grade_id": "cell-79ab1e6f1ab4b201",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "4S4jFsxOXyTn"
      },
      "source": [
        "4. Find the best threshold using Newton's method.\n",
        "\n",
        "Implement a function loss_best_threshold_newton\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "f - rat_classification_loss_deriv\n",
        "x0 = 0 - starting point\n",
        "niter = 10 - number of iterations\n",
        "return value - the best threshold according to the loss function\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b9f23f0547c078b78e338ee9c1e5a18a",
          "grade": false,
          "grade_id": "cell-94bc44c21f3a1b2f",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "ZHmsUL9vXyTo"
      },
      "source": [
        "def loss_best_threshold_newton(f, x0=0., niter=10):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "73d2453233567d76e959b54952ada334",
          "grade": true,
          "grade_id": "cell-e03d19aad1688287",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "TsMe8sFmXyTo"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q2.4 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'loss' function..\\n \")\n",
        "best_threshold = loss_best_threshold_newton(rat_classification_loss_deriv)\n",
        "assert best_threshold > 0\n",
        "assert rat_classification_loss(best_threshold) < rat_classification_loss(best_threshold+0.5)\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "a8a558fbb7427640df46a87857950f77",
          "grade": false,
          "grade_id": "cell-d908eaa6fd1bc3f7",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "QFlFAHa1XyTo"
      },
      "source": [
        "5. Using the best threshold found, how many diabetes=1 cases were misclassified?\n",
        "\n",
        "Implement a function misclassified_diabetes\n",
        "\n",
        "<pre>\n",
        "Input parameters:\n",
        "data - the data in the format of list of tuples\n",
        "use_newton - True if using Newton, False if using GD\n",
        "return value - how many diabetes=1 cases were missclassified\n",
        "</pre>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fa9602ebce442326ee3c07e3346eb339",
          "grade": false,
          "grade_id": "cell-cfdeadebe7272bf1",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "dBV41VBGXyTo"
      },
      "source": [
        "def misclassified_diabetes(use_newton=False, data=rats):\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f56662b27ccd2a2a332e790e876136ef",
          "grade": true,
          "grade_id": "cell-a6bf63dd69b400cc",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "Qb2nJJdbXyTp"
      },
      "source": [
        "# --------------------------- RUN THIS TEST CODE CELL -------------------------------------\n",
        "# Q2.5 --- Test your implementation:\n",
        "# ---------------------------\n",
        "print(\"Testing the implementation of the 'loss' function..\\n \")\n",
        "missclassified_diabetes_count_gd = misclassified_diabetes(False)\n",
        "missclassified_diabetes_count_newton = misclassified_diabetes(True)\n",
        "assert missclassified_diabetes_count_gd >= 0\n",
        "assert missclassified_diabetes_count_newton >= 0\n",
        "print (\"good job!\\nSanity tests passed. There are additional hidden tests...\")\n",
        "print(f\"Number of missclasifications: {missclassified_diabetes_count_gd}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}